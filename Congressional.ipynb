{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "#Boosting\n",
    "#Decision Tree\n",
    "#Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm \n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "def type_to_numeric(x):\n",
    "    if x == 'democrat':\n",
    "        return 0\n",
    "    if x == 'republican':\n",
    "        return 1\n",
    "    if x == 'n':\n",
    "        return 0\t\n",
    "    if x == 'y':\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the data from the file\n",
    "def read_data(file):\n",
    "\n",
    "    data_file = pd.read_csv('congressional_data.txt', sep=\"\\t\", header = None)\n",
    "    data_file.columns = [\"Party\",\"handicapped_infants\",\"water_project_cost_sharing\",\"adoption_of_the_budget_resolution\",\"physician_fee_freeze\",\t\"el_salvador_aid\",\t\"religious_groups_in_schools\",\t\"nti_satellite_test_ban\",\"aid_to_nicaraguan_contras\",\"mx_missile\", \"immigration\",\"synfuels_corporation_cutback\",\"education_spending\",\"superfund_right_to_sue\",\t\"crime\",\"duty_free_exports\",\"export_administration_act_sa\"]\n",
    "\n",
    "    columns = [\"Party\",\"handicapped_infants\",\"water_project_cost_sharing\",\"adoption_of_the_budget_resolution\",\"physician_fee_freeze\",\t\"el_salvador_aid\",\t\"religious_groups_in_schools\", \"nti_satellite_test_ban\",\"aid_to_nicaraguan_contras\",\"mx_missile\",\"immigration\",\"synfuels_corporation_cutback\",\"education_spending\",\"superfund_right_to_sue\",\t\"crime\",\"duty_free_exports\",\"export_administration_act_sa\"]\n",
    "\n",
    "    for column in columns:\n",
    "        data_file[column] = data_file[column].apply(type_to_numeric)\n",
    "\n",
    "\n",
    "    data_file_updated = data_file.dropna()\n",
    "    \n",
    "    \n",
    "    data = data_file_updated[[\"handicapped_infants\",\t\"water_project_cost_sharing\",\t\"adoption_of_the_budget_resolution\",\t\n",
    "        \"physician_fee_freeze\",\t\"el_salvador_aid\",\t\"religious_groups_in_schools\",\t\"nti_satellite_test_ban\",\t\n",
    "        \"aid_to_nicaraguan_contras\",\t\"mx_missile\",\t\"immigration\",\t\"synfuels_corporation_cutback\",\t\n",
    "        \"education_spending\",\t\"superfund_right_to_sue\",\t\"crime\",\t\n",
    "        \"duty_free_exports\",\t\"export_administration_act_sa\"]]\n",
    "    label = data_file_updated[\"Party\"]\n",
    "\n",
    "    return np.array(data), np.array(label)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Accuracy of the results\n",
    "def accuracy(true_class, pred_class):           #Calculating the accuracy of the classification\n",
    "    correct = 0\n",
    "    for x in range(len(true_class)):\n",
    "        if true_class[x] == pred_class[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(true_class))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize runtime\n",
    "start = time.clock()\n",
    "\n",
    "#Reading the data from the txt file( Two variables)\n",
    "data, label = read_data(\"datafile.txt\")\n",
    "\n",
    "#Splitting the data\n",
    "dtrain, data_tc, dtr_label, dtc_label = train_test_split(data, label, test_size=0.20, random_state=1)\n",
    "dtest, dval, dtest_label, dval_label = train_test_split(data_tc,dtc_label, test_size=0.25, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The accuracy of the prediction when SVM is used: ', 100.0)\n",
      "('Error Performance when SVM is used: ', 0.0)\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine Algorithm\n",
    "\n",
    "#Validation Step\n",
    "max_score = 0\n",
    "max_reg = 0\n",
    "max_kernel = 0\n",
    "kernels = [\"linear\",\"rbf\",\"poly\"]\n",
    "for v in range(1,5):\n",
    "    for k in kernels:\n",
    "        SVM = svm.SVC(C= v, kernel = k)\n",
    "        SVM.fit(dtrain, dtr_label)\n",
    "        if(SVM.score(dval,dval_label) > max_score):\n",
    "            max_score = SVM.score(dval,dval_label)\n",
    "            max_reg = v\n",
    "            max_kernel = k\n",
    "\n",
    "\n",
    "#Fitting the test data\n",
    "SVM = svm.SVC(C= max_reg, kernel = max_kernel)\n",
    "fit = SVM.fit(dtrain,dtr_label)\t\t\n",
    "\n",
    "#Predicting the data test into class\n",
    "true_class_svm = dtest_label\n",
    "pred_class_svm = SVM.predict(dtest)\n",
    "\n",
    "#Assesing the accuracy of the predicted class\n",
    "svm_acc = accuracy(true_class_svm,pred_class_svm)\n",
    "\n",
    "#Printing the accuracy of prediction\n",
    "print( \"The accuracy of the prediction when SVM is used: \", svm_acc )\n",
    "print(\"Error Performance when SVM is used: \", 100-svm_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The accuracy of the prediction when Adaboost is used: ', 94.28571428571428)\n",
      "('Error Performance when Adaboost is used: ', 5.714285714285722)\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Algorithm\n",
    "\n",
    "#Validation Step\n",
    "max_score = 0\n",
    "max_estimators = 0\n",
    "max_learningrate = 0\n",
    "for e in range(50,600,50):\n",
    "    for l in range(1,4,1):\n",
    "        adaboost = AdaBoostClassifier(n_estimators= e, learning_rate= l)\n",
    "        adaboost.fit(dtrain, dtr_label)\n",
    "        if(adaboost.score(dval,dval_label) > max_score):\n",
    "            max_score = adaboost.score(dval,dval_label)\n",
    "            max_estimators = e\n",
    "            max_learningrate = l\n",
    "\n",
    "#Fitting the test data\n",
    "adaboost = AdaBoostClassifier(n_estimators = max_estimators, learning_rate = max_learningrate)\n",
    "fit = adaboost.fit(dtrain,dtr_label)\t\t\n",
    "\n",
    "\n",
    "#Predicting the data test into class\n",
    "true_class_adaboost = dtest_label\n",
    "pred_class_adaboost = adaboost.predict(dtest)\n",
    "\n",
    "#Assesing the accuracy of the predicted class\n",
    "adaboost_acc = accuracy(true_class_adaboost,pred_class_adaboost)\n",
    "\n",
    "#Printing the accuracy of prediction\n",
    "print( \"The accuracy of the prediction when Adaboost is used: \", adaboost_acc )\n",
    "print(\"Error Performance when Adaboost is used: \", 100-adaboost_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The accuracy of the prediction when Decision Tree Classifier is used: ', 100.0)\n",
      "('Error Performance when Decision Tree Classifier is used: ', 0.0)\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Algorithm\n",
    "\n",
    "#Validation Step\n",
    "max_score = 0\n",
    "max_depth = 0\n",
    "for d in range(1,10):\n",
    "    dtc = DecisionTreeClassifier(max_depth = d)\n",
    "    dtc.fit(dtrain, dtr_label)\n",
    "    if(dtc.score(dval,dval_label) > max_score):\n",
    "        max_score = dtc.score(dval,dval_label)\n",
    "        max_depth = d\n",
    "\n",
    "\n",
    "#Fitting the test data\n",
    "dtc = DecisionTreeClassifier(max_depth= max_depth)\n",
    "fit = dtc.fit(dtrain,dtr_label)\t\t\n",
    "\n",
    "#Predicting the data test into class\n",
    "true_class_dtc = dtest_label\n",
    "pred_class_dtc = dtc.predict(dtest)\n",
    "\n",
    "#Assesing the accuracy of the predicted class\n",
    "dtc_acc = accuracy(true_class_dtc,pred_class_dtc)\n",
    "\n",
    "#Printing the accuracy of prediction\n",
    "print (\"The accuracy of the prediction when Decision Tree Classifier is used: \", dtc_acc) \n",
    "print (\"Error Performance when Decision Tree Classifier is used: \", 100-dtc_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The accuracy of the prediction when Neural Network Classifier is used: ', 91.42857142857143)\n",
      "('Error Performance when Neural Network Classifier is used: ', 8.57142857142857)\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "\n",
    "#Validation Step\n",
    "max_score = 0\n",
    "max_hidden_layers = 0\n",
    "max_alpha = 0\n",
    "max_solver = 0\n",
    "solvers = [\"lbfgs\", \"sgd\", \"adam\"] \n",
    "for h in range(5,100,5):\n",
    "    for s in solvers:\n",
    "        neural = MLPClassifier(solver= s, hidden_layer_sizes=(h,))\n",
    "        neural.fit(dtrain, dtr_label)\n",
    "        if(neural.score(dval,dval_label) > max_score):\n",
    "            max_score = neural.score(dval,dval_label)\n",
    "            max_hidden_layers = h\n",
    "            max_solver = s\n",
    "\n",
    "\n",
    "#Fitting the test data\n",
    "neural = MLPClassifier(solver = max_solver, hidden_layer_sizes=(max_hidden_layers,))\n",
    "fit = neural.fit(dtrain,dtr_label)\t\t\n",
    "\n",
    "#Predicting the data test into class\n",
    "true_class_neural = dtest_label\n",
    "pred_class_neural = neural.predict(dtest)\n",
    "\n",
    "#Assesing the accuracy of the predicted class\n",
    "neural_acc = accuracy(true_class_neural,pred_class_neural)\n",
    "\n",
    "#Printing the accuracy of prediction\n",
    "print( \"The accuracy of the prediction when Neural Network Classifier is used: \", neural_acc )\n",
    "print(\"Error Performance when Neural Network Classifier is used: \", 100-neural_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inferences and Conclusions:\n",
    "    \n",
    "Congressional Dataset consists of 435 instances with 16 variables. It consists of Missing values, and upon \n",
    "filtration we end up with 232 instances.\n",
    "\n",
    "We have used four different models to learn the data and perform the prediction task. \n",
    "They are:\n",
    "\n",
    "Support Vector Machines(SVM)\n",
    "Boosting(Adaboost Algorithm)\n",
    "CART (Decision Tree Algorithm)\n",
    "Neural Network\n",
    "\n",
    "In the Support Vector Machines algorithm, we have used Regularisation Parameter and type of Kernel as the varying \n",
    "factor for the validation step and we performed the analysis. On checking with different results, we have observed\n",
    "that prediction rate is highest for Linear Classifier and unit regularisation parameter. While, as we moved to other\n",
    "kernels and higher regularisation parameters, it reduced.\n",
    "\n",
    "When we come to Adaboost model, we have used learning rate and number of estimators as the varying factor. \n",
    "Decision Tree Classifier remained as its default model and SAMME as its default algorithm. In this algorithm, we \n",
    "have observed that for higher values of number of estimators and learning rate the prediction accuracy is less.\n",
    "So for the values of 50 estimators and learning rate to be 1. We have the highest prediction accuracy.\n",
    "\n",
    "In case Decision tree classifier, we have used maximum depth as the varying factor and came to know that\n",
    "for the smaller value of smaller depth, we have observed a highest prediction rate.\n",
    "\n",
    "Ultimately, for neural networks we have used the type of solver and number of hidden layers as the varying factor\n",
    "and we have observed that the solver \"lgfbs\" and for 10 hidden layers we are getting the highest accuracy.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
